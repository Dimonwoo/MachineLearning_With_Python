## Index
![grape](https://user-images.githubusercontent.com/12748752/126882595-d1f5449e-14bb-4ab3-809c-292caf0858a1.png)
![plum](https://user-images.githubusercontent.com/12748752/126882596-b9ba4645-7001-435e-9a3c-d4416a2543c1.png)

## Batch Gradient Descent
![plum](https://user-images.githubusercontent.com/12748752/126882596-b9ba4645-7001-435e-9a3c-d4416a2543c1.png)
### Partial Derivative
* To implement Gradient Descent, you need to compute the gradient of the cost function with regard to each model parameter **_<a>&theta;</a><sub>j</sub>_** .
* In other words, you need to calculate how much the cost function will change if you change **_<a>&theta;</a>_** just a little bit. 
* This is called a partial derivative.
