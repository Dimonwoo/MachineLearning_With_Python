{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06df0ba-187a-40b6-8483-4133ddf2d4f6",
   "metadata": {},
   "source": [
    "### Regression Data split-model-evaluation:\n",
    "![dark](https://user-images.githubusercontent.com/12748752/126882595-d1f5449e-14bb-4ab3-809c-292caf0858a1.png)\n",
    "First import ***`train_test_split()`*** and ***`load_boston()`***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3592b343-2a5a-4c1c-993f-2d81367f4ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b2fc3-de32-4605-ba65-0fa3b45184ed",
   "metadata": {},
   "source": [
    "### _Load the Data_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f63fc7e6-f78e-4343-a3ca-221a9ea28323",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a661fe-46a6-46a1-b416-dca7597a7eaa",
   "metadata": {},
   "source": [
    "### _Split the Data_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ab04d29-324c-4022-8e9f-68197ccf3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ceb1ea-5cbc-45f2-a991-ebf112c36e36",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "![light](https://user-images.githubusercontent.com/12748752/126882596-b9ba4645-7001-435e-9a3c-d4416a2543c1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce546d2b-1e1f-4521-b52f-d90ff41cd010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_model = LinearRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf2dc9c-3e3a-4d74-925b-79c1ab67609d",
   "metadata": {},
   "source": [
    "### Note:\n",
    "**LinearRegression** creates the object that represents the model, while **.fit()** trains, or fits, the model and returns it. With **linear regression**, fitting the model means determining the **best intercept (model.intercept_)** and **slope (model.coef_) values** of the regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e598dbd9-b6f9-473c-aede-ad521fc9af24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Y intercept value is= 34.33026076546659 and the best slope value is= [-1.13498178e-01  3.79976868e-02  2.99876109e-02  3.51131977e+00\n",
      " -1.44513558e+01  3.80534175e+00 -1.79553906e-02 -1.48968845e+00\n",
      "  2.53016064e-01 -1.00262729e-02 -8.86408743e-01  1.08462004e-02\n",
      " -5.75917903e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"The best Y intercept value is= {} and the best slope value is= {}\".format(lr_model.intercept_,lr_model.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167f2b00-2322-4242-a49e-cf6964921538",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor\n",
    "![light](https://user-images.githubusercontent.com/12748752/126882596-b9ba4645-7001-435e-9a3c-d4416a2543c1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cff70dbb-a3c9-4013-b918-e2a7e0261fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr_model = GradientBoostingRegressor(random_state=0).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5af6eb-3054-4bdb-9179-7a5f2f7e1a2a",
   "metadata": {},
   "source": [
    "### Random Forest Regressor\n",
    "![light](https://user-images.githubusercontent.com/12748752/126882596-b9ba4645-7001-435e-9a3c-d4416a2543c1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f7dadc2-b2a6-4bdd-9bc5-ee1fad3aafbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr_model = RandomForestRegressor(random_state=0).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26846740-1ba5-4a9c-b225-08841a7f3955",
   "metadata": {},
   "source": [
    "## Error or Loss or Cost\n",
    "![dark](https://user-images.githubusercontent.com/12748752/126882595-d1f5449e-14bb-4ab3-809c-292caf0858a1.png)\n",
    "> #### We don't calculate accuracy for a regression model.The **skill** or **performance** of a regression model must be reported as an **_Error_** in those predictions.\n",
    "\n",
    "### Non Matrix\n",
    "![light](https://user-images.githubusercontent.com/12748752/126882596-b9ba4645-7001-435e-9a3c-d4416a2543c1.png)\n",
    "1) **Import** the classes you need.\n",
    "2) **Create** model instances using these classes.\n",
    "3) **Fit** the model instances with **.fit()** using the training set.\n",
    "4) **Evaluate** the model with **.score()** using the test set.\n",
    "\n",
    "\n",
    "### _R <sup>2</sup> Error_ or _Coefficient of Determination_\n",
    "**.score()** returns the **coefficient of determination**, or **R<sup>2</sup>**, for the data passed. Its maximum is **1**. The higher the **R<sup>2</sup>** value, the better the fit. In this case, the training data yields a slightly higher coefficient. However, the **R<sup>2</sup>** calculated with test data is an unbiased measure of your modelâ€™s prediction performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccde292-e2de-4429-8b7e-6f5a1b08fb1c",
   "metadata": {},
   "source": [
    "### For _Linear Regression_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "112d6b78-0438-4589-a25d-c35a15b94ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train_data score is= 0.747199884740759 and the test_data score is= 0.7125140936111218\n"
     ]
    }
   ],
   "source": [
    "print(\"The train_data score is= {} and the test_data score is= {}\".format(lr_model.score(x_train, y_train),lr_model.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0752463c-c411-43f3-a8bc-10e145b345de",
   "metadata": {},
   "source": [
    "### For _Gradient Boosting Regressor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f3dea8e-ebe9-4b5a-a692-f4216c2ffa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train_data score is= 0.9827347423881452 and the test_data score is= 0.8881997684801992\n"
     ]
    }
   ],
   "source": [
    "print(\"The train_data score is= {} and the test_data score is= {}\".format(gbr_model.score(x_train, y_train),gbr_model.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd2daa9-ceb2-4d44-8657-d942263ca2aa",
   "metadata": {},
   "source": [
    "### For _Random Forest Regressor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7b6e22f-d07f-4486-8b66-f24716da779e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train_data score is= 0.9763981233461205 and the test_data score is= 0.8595796677090435\n"
     ]
    }
   ],
   "source": [
    "print(\"The train_data score is= {} and the test_data score is= {}\".format(rfr_model.score(x_train, y_train),rfr_model.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935244ab-9794-4846-8555-47dbce064946",
   "metadata": {},
   "source": [
    "## Error Matrix\n",
    "![light](https://user-images.githubusercontent.com/12748752/126882596-b9ba4645-7001-435e-9a3c-d4416a2543c1.png)\n",
    "### Non Matrix\n",
    "1) **Import** the classes you need.\n",
    "2) **Create** model instances using these classes.\n",
    "3) **Fit** the model instances with **.fit()** using the training set.\n",
    "4) **Evaluate** the model with **.predict()** using the test set.\n",
    "5) **Error difference** comparing **Y<sub>actual</sub>** from **Y<sub>predicted</sub>**\n",
    "\n",
    "#### There is no correct value for those matrixes. Simply put, the lower the value the better and **0** means the model is perfect. \n",
    "\n",
    "### There are **three error metrics** that are commonly used for evaluating and reporting the performance of a regression model; they are:\n",
    "1) **_Mean Squared Error (MSE)_**.\n",
    "2) **_Root Mean Squared Error (RMSE)_**.\n",
    "3) **_Mean Absolute Error (MAE)_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "541a3e0f-4fb2-4e7e-8333-99ae3edca55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9253674-4fee-4a8d-9fec-9ae28df7a47c",
   "metadata": {},
   "source": [
    "### For _Linear Regression_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "783a0554-c6ba-46dc-a6e2-7d7af555790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:21.832709989577474  MAE:3.2979696834924157 RMSE:4.672548554009629\n"
     ]
    }
   ],
   "source": [
    "y_hat = lr_model.predict(x_test)\n",
    "mse = mean_squared_error(y_test,y_hat)\n",
    "mae = mean_absolute_error(y_test,y_hat)\n",
    "rmse= mean_squared_error(y_test, y_hat, squared=False)\n",
    "print(\"MSE:{}  MAE:{} RMSE:{}\".format(mse,mae,rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f011c801-b35d-4ce4-9922-ab08fd448347",
   "metadata": {},
   "source": [
    "### For _Gradient Boosting Regresson_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55a7734a-8f1d-413f-9566-bb24f218075b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:8.490510238222443  MAE:1.9778134646722885 RMSE:2.9138480122035264\n"
     ]
    }
   ],
   "source": [
    "y_hat = gbr_model.predict(x_test)\n",
    "mse = mean_squared_error(y_test,y_hat)\n",
    "mae = mean_absolute_error(y_test,y_hat)\n",
    "rmse= mean_squared_error(y_test, y_hat, squared=False)\n",
    "print(\"MSE:{}  MAE:{} RMSE:{}\".format(mse,mae,rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88325df7-bee4-406a-9cf0-da73f0bd1cf7",
   "metadata": {},
   "source": [
    "### For _Random Forest Regresson_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2834919-1670-496f-a3fc-2ad8478a0304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:10.664023256157634  MAE:2.209600985221675 RMSE:3.2655816107023927\n"
     ]
    }
   ],
   "source": [
    "y_hat = rfr_model.predict(x_test)\n",
    "mse = mean_squared_error(y_test,y_hat)\n",
    "mae = mean_absolute_error(y_test,y_hat)\n",
    "rmse= mean_squared_error(y_test, y_hat, squared=False)\n",
    "print(\"MSE:{}  MAE:{} RMSE:{}\".format(mse,mae,rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
